{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfd78cea",
   "metadata": {},
   "source": [
    "# Module 1 : Exploring BM25 similarity and Semantic similarity\n",
    "\n",
    "Before we get started with Amazon OpenSearch and our search web app, let's explore some of the core concepts in search. Below, we'll demonstrate the different between algorithms for matching data using BM25 similarity (keyword matching) and Cosine similarity (sematnic vector matching)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6e453",
   "metadata": {},
   "source": [
    "### 1. Upgrade PyTorch and restart Kernel\n",
    "\n",
    "Before we begin, we need to upgrade PyTorch and restart the notebook kernel. The following should take 2-3 minutes to complete, and you should see the following message::\"Successfully intalled torch-1.nn.n\".\n",
    "\n",
    "You may see a message with stating \"ERROR: pip's dependency resolver does not...\" - you can ignore this error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff8b447e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (1.4.0)\n",
      "Collecting torch\n",
      "  Downloading torch-1.10.2-cp36-cp36m-manylinux1_x86_64.whl (881.9 MB)\n",
      "     |████████████████████████████████| 881.9 MB 7.8 kB/s              \n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (3.10.0.0)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch) (0.8)\n",
      "Installing collected packages: torch\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 1.4.0\n",
      "    Uninstalling torch-1.4.0:\n",
      "      Successfully uninstalled torch-1.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "fastai 1.0.61 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "Successfully installed torch-1.10.2\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145328b8",
   "metadata": {},
   "source": [
    "Now we need to restart the kernel by running below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea346d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>Jupyter.notebook.kernel.restart()</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display_html\n",
    "def restartkernel() :\n",
    "    display_html(\"<script>Jupyter.notebook.kernel.restart()</script>\",raw=True)\n",
    "restartkernel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df1c943b",
   "metadata": {},
   "source": [
    "Next, let's verify the version of Torch to ensure everything is up to date. The version should be 1.10.2 or higher."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96788429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.2+cu102\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610273a4",
   "metadata": {},
   "source": [
    "### 2. Install Pre-Requisites\n",
    "\n",
    "Before we can experiment with different searches, we need to install some required libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ee6ec249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     |████████████████████████████████| 85 kB 6.9 MB/s             \n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting rank_bm25\n",
      "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers) (4.18.0)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers) (4.61.1)\n",
      "Requirement already satisfied: torch>=1.6.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers) (1.10.2)\n",
      "Requirement already satisfied: torchvision in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers) (0.5.0)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers) (1.19.5)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers) (0.24.2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers) (1.5.3)\n",
      "Requirement already satisfied: nltk in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers) (3.6.2)\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp36-cp36m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     |████████████████████████████████| 1.3 MB 82.3 MB/s            \n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub>=0.4.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sentence-transformers) (0.4.0)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.25.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (21.3)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.0.12)\n",
      "Requirement already satisfied: pyyaml in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (5.4.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.10.0.0)\n",
      "Requirement already satisfied: importlib-metadata in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.5.0)\n",
      "Requirement already satisfied: dataclasses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torch>=1.6.0->sentence-transformers) (0.8)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2021.4.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.12.1)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.0.53)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nltk->sentence-transformers) (1.0.1)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from nltk->sentence-transformers) (8.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn->sentence-transformers) (2.1.0)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->sentence-transformers) (1.16.0)\n",
      "Requirement already satisfied: pillow>=4.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from torchvision->sentence-transformers) (8.4.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from packaging>=20.9->huggingface-hub>=0.4.0->sentence-transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from importlib-metadata->huggingface-hub>=0.4.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (1.26.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2021.5.30)\n",
      "Building wheels for collected packages: sentence-transformers\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=126546 sha256=555a49a260634a382979eb6985b3108d033a074b786c0808fda91e35f2c58183\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/c9/90/11/0e58d454669bc8daf94e04a8da9956aa6f78eb10cddb16dd4e\n",
      "Successfully built sentence-transformers\n",
      "Installing collected packages: sentencepiece, sentence-transformers, rank-bm25\n",
      "Successfully installed rank-bm25-0.2.2 sentence-transformers-2.2.2 sentencepiece-0.1.97\n"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers\n",
    "!pip install -U sentence-transformers rank_bm25\n",
    "\n",
    "from rank_bm25 import BM25Okapi\n",
    "from sklearn.feature_extraction import _stop_words\n",
    "import string\n",
    "from tqdm.autonotebook import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8253c09f",
   "metadata": {},
   "source": [
    "### 3. Create a sample dataset\n",
    "\n",
    "Let's now create a very simple dataset as an array of 4 questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3fc7176",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages=[\"does this work with xbox?\",\n",
    "          \"Does the M70 work with Android phones?\", \n",
    "          \"does this work with iphone?\",\n",
    "          \"Can this work with an xbox \"\n",
    "         ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc496f65",
   "metadata": {},
   "source": [
    "### 4. Explore BM25 similarity \n",
    "\n",
    "Execute the following to explore BM25 similarity. First, we'll tokenize the data set, then use BM25 similarity to compare the phrase \"does this work with xbox?\" with our sample questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d1727b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cb3198028b441f086bbe4a8b74376c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top most similar pairs:\n",
      "does this work with xbox? \t ['does', 'work', 'xbox'] \t 0.0255\n",
      "does this work with iphone? \t ['does', 'work', 'iphone'] \t 0.0255\n",
      "Does the M70 work with Android phones? \t ['does', 'm70', 'work', 'android', 'phones'] \t 0.0198\n",
      "Can this work with an xbox  \t ['work', 'xbox'] \t 0.0149\n"
     ]
    }
   ],
   "source": [
    "# split the sentence into words and remove stop words. For example setence \"does this work with xbox\" \n",
    "# will be converted into words \"does\", \"work\", \"xbox\"\n",
    "def bm25_tokenizer(text):\n",
    "    tokenized_doc = []\n",
    "    for token in text.lower().split():\n",
    "        token = token.strip(string.punctuation)\n",
    "\n",
    "        if len(token) > 0 and token not in _stop_words.ENGLISH_STOP_WORDS:\n",
    "            tokenized_doc.append(token)\n",
    "    return tokenized_doc\n",
    "\n",
    "\n",
    "tokenized_corpus = []\n",
    "for passage in tqdm(passages):\n",
    "    tokenized_corpus.append(bm25_tokenizer(passage))\n",
    "\n",
    "#get the BM25 score between the query \"does this work with xbox?\" and exiting 4 questions above. \n",
    "#If the score is high, it means BM25 think the two sentences are similiar.\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "bm25_scores = bm25.get_scores(bm25_tokenizer(\"does this work with xbox?\"))\n",
    "\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(bm25_scores)):\n",
    "    all_sentence_combinations.append([bm25_scores[i], i])\n",
    "\n",
    "#sort the score descending\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# print the 4 sentences, tokens and the BM25 score with query \"does this work with xbox?\"\n",
    "# You can \"does this work with iphone?\" has high BM25 score with \"does this work with xbox?\" \n",
    "# even though the semantics meaning is different. While \"Can this work with an xbox\" has low BM25 score \n",
    "# with \"does this work with xbox?\" even though the two sentence has same semantic meaning. \n",
    "# This is the drawback of BM25.\n",
    "print(\"Top most similar pairs:\")\n",
    "for score, i in all_sentence_combinations[0:4]:\n",
    "    print(\"{} \\t {} \\t {:.4f}\".format(passages[i],bm25_tokenizer(passages[i]),bm25_scores[i]))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a24396bc",
   "metadata": {},
   "source": [
    "### 5. Semantic Similarities\n",
    "\n",
    "\n",
    "Execute the following to explore semantic similarity with cosine similarity. In this code, we'll use the same dataset as above, but using cosine similarity. Compare the differences in how similarity is measured.\n",
    "\n",
    "The 'all-MiniLM-L6-v2' is a sentence transformer from HuggingFace that maps sentences & paragraphs to a 384 dimensional dense vector space. We'll use this library to translate our sample data set to a vector set. We'll then use util.cos_sim to provide a cosine similarity between each combination of records in the dataset. Finally, we'll print the cosine similarity score of the first record (\"does this work with xbox?\") with records in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "541af7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f08484b519b4d3c90f13c231d1b2c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0286d4b25cf547389d9d4806aa63b254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73983305155c4f838160065567ebb4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e088a7feecab45a6bdbdd924a12ea942",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e47fc5ae8224ba5b5a467d5c33f7ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "344cb85c3eef40c1b98699a6205af15f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bac4f7f850410cb0270eb4200eca6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32c0b9f99fca49d982739a00d70711b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50ea3e648144d02bbcc0c158a1be90a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e784e4d6d94a4bd2b429ccc4072fcc44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c35cdcf67720498b90979a64e1e691b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6602ccfde184f17a0ce39de92a80573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e04942345d2540d3a94f7e463c449137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aae635dab5f64a8f862393a0136f3684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top most similar pairs:\n",
      "does this work with xbox? \t 1.0000\n",
      "Can this work with an xbox  \t 0.9444\n",
      "does this work with iphone? \t 0.4522\n",
      "Does the M70 work with Android phones? \t 0.3235\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "#Encode all sentences\n",
    "embeddings = model.encode(passages)\n",
    "\n",
    "#Compute cosine similarity between all pairs\n",
    "cos_sim = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#cosine similarity score with query\n",
    "all_sentence_combinations = []\n",
    "for i in range(len(cos_sim)):\n",
    "    all_sentence_combinations.append([cos_sim[0][i], i])\n",
    "\n",
    "#Sort list by the highest cosine similarity score\n",
    "all_sentence_combinations = sorted(all_sentence_combinations, key=lambda x: x[0], reverse=True)\n",
    "\n",
    "# You see \"does this work with xbox?\" has the same meaning with query \"does this work with xbox?\", \n",
    "# so the semantic score is highest of course. \"Can this work with an xbox\" has similiar meaning \n",
    "# with \"does this work with xbox?\", semantic score ranked second.\n",
    "print(\"Top most similar pairs:\")\n",
    "for score, i in all_sentence_combinations[0:4]:\n",
    "    print(\"{} \\t {:.4f}\".format(passages[i],cos_sim[0][i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa12d75b",
   "metadata": {},
   "source": [
    "### 6. Compare the differences.\n",
    "\n",
    "As you can see, the similarity is significantly different, even with with a trivial data set. In particular, observe the differences between the text for \"Can this work with an xbox\" - with BM25 keyword search, the word \"can\" doesn't match the original question, and so it's given a low rating. Cosine similarity semantic search provides a much better match in this case.\n",
    "\n",
    "In this module, we've used fairly simple steps with a very small dataset to demonstrate the difference between BM25 and cosine similarity. In the following modules, we'll demonstrate these same concepts with using OpenSearch and a larger and more complex dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
